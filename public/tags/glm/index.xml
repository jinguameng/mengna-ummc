<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>glm | Mengna&#39;s Space</title>
    <link>/tags/glm/</link>
      <atom:link href="/tags/glm/index.xml" rel="self" type="application/rss+xml" />
    <description>glm</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 27 Feb 2020 15:56:36 -0600</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>glm</title>
      <link>/tags/glm/</link>
    </image>
    
    <item>
      <title>Note8 Glm Diagnostics</title>
      <link>/post/note8-glm-diagnostics/</link>
      <pubDate>Thu, 27 Feb 2020 15:56:36 -0600</pubDate>
      <guid>/post/note8-glm-diagnostics/</guid>
      <description>


&lt;div id=&#34;assessing-the-link-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span style=&#34;color:red&#34;&gt;Assessing the Link Function&lt;/span&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Pregibon link test&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Run GLM.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Obtain fitted values for linear predictor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create new variables &lt;span class=&#34;math inline&#34;&gt;\((X\hat{\beta})^2\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Run model with &lt;span class=&#34;math inline&#34;&gt;\(X\hat{\beta} + (X\hat{\beta})^2\)&lt;/span&gt; as predictors.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;evaluate: if p-value is not significant for &lt;span class=&#34;math inline&#34;&gt;\((X\hat{\beta})^2\)&lt;/span&gt; term, link function is correctly specified.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;a3p2c1.PNG&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The p-value for _hatsq is greater 0.05 which is not statistically significant indicatiing that the model seems to be well specified.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;outlier-detection&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span style=&#34;color:red&#34;&gt;Outlier Detection&lt;/span&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Cook’s distance measures the aggregate change in the estimated coefficients when each observation is left out of the estimation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;rules-of-thumb&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rules of thumb:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(C_i &amp;gt; \frac{4}{n-p-1}\)&lt;/span&gt; n = number of total observations. p = number of coefficients&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(C_i &amp;gt; \frac{3\sum{C_i}}{n}\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(C_i &amp;gt; 1\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;r-square&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span style=&#34;color:red&#34;&gt;R-square&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;In ordinary least squares(OLS) regression, &lt;span class=&#34;math inline&#34;&gt;\(R^2 = 1 - \frac{\sum_{i=1}^N(y_i - \hat{y_i})^2}{\sum_{i=1}^N(y_i - \bar{y})^2}\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;N is the number of pbservations in the model.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;y is the dependent variable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;y-hat is the value predicted by the model.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; is typically interpreted as % variance explained, but &lt;span class=&#34;math inline&#34;&gt;\(Pseudo-R^2 = (correlation(y,\hat{y}))^2\)&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;information-criteria&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span style=&#34;color:red&#34;&gt;Information Criteria&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;The AIC and BIC are two popular measures for comparing maximum likelihood models.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span style=&#34;color:orange&#34;&gt;AIC = Akaike Information Criterion&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(AIC = -2*ln(likelihood) + 2*k\)&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;BIC = Bayesian Information Criterion&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(BIC = -2*ln(likelihood) + ln(N)*k\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;k = number of parameters estimated&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;N = number of observations&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;AIC and BIC can be viewed as measures that combine fit and complexity.&lt;/p&gt;
&lt;p&gt;Fit is measured negatively by −2 × ln(likelihood); the larger the value, the worse the fit.&lt;/p&gt;
&lt;p&gt;Complexity is measured positively, either by 2 × k (AIC) or ln(N) × k (BIC).&lt;/p&gt;
&lt;p&gt;&lt;span style=&#34;color:pink&#34;&gt;Given two models fit on the same data, the model with the smaller value of the information criterion is considered to be better.&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;section&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&amp;lt;&amp;gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.stata.com/manuals/rbicnote.pdf&#34; class=&#34;uri&#34;&gt;https://www.stata.com/manuals/rbicnote.pdf&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
